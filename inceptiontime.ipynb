{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import","metadata":{"id":"0V39PkX6VYU6"}},{"cell_type":"code","source":"import os\nimport copy\nimport time\nimport sys\nimport random\nimport timeit\n\nimport numpy as np\nimport scipy.signal\nimport scipy.io\n\nimport pandas as pd\n\nimport itertools\nfrom itertools import product\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('seaborn-whitegrid')\nplt.rcParams.update({'font.size': 32})\nplt.rcParams[\"figure.figsize\"] = (12,8)\n# import seaborn as sns","metadata":{"id":"FYyQnvfQVYVs","execution":{"iopub.status.busy":"2022-07-20T06:25:22.358960Z","iopub.execute_input":"2022-07-20T06:25:22.359513Z","iopub.status.idle":"2022-07-20T06:25:22.370191Z","shell.execute_reply.started":"2022-07-20T06:25:22.359472Z","shell.execute_reply":"2022-07-20T06:25:22.368708Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"try:\n    import tqdm\nexcept:\n    !pip install tqdm\nfinally:\n    from tqdm.notebook import tqdm, trange","metadata":{"id":"7kSmlNU65nEq","execution":{"iopub.status.busy":"2022-07-20T06:25:22.788769Z","iopub.execute_input":"2022-07-20T06:25:22.790039Z","iopub.status.idle":"2022-07-20T06:25:22.901709Z","shell.execute_reply.started":"2022-07-20T06:25:22.789979Z","shell.execute_reply":"2022-07-20T06:25:22.900561Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data\n\n\nfrom torchvision import transforms, datasets\nimport torchvision.transforms as T","metadata":{"id":"RNQECtYTFRMS","execution":{"iopub.status.busy":"2022-07-20T06:25:23.408035Z","iopub.execute_input":"2022-07-20T06:25:23.408836Z","iopub.status.idle":"2022-07-20T06:25:25.566521Z","shell.execute_reply.started":"2022-07-20T06:25:23.408807Z","shell.execute_reply":"2022-07-20T06:25:25.565185Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"try:\n    import torchsummary\nexcept:\n    !pip install torchsummary\nfinally:\n    import torchsummary","metadata":{"id":"_MqRq52y64nC","execution":{"iopub.status.busy":"2022-07-20T06:25:25.568997Z","iopub.execute_input":"2022-07-20T06:25:25.569606Z","iopub.status.idle":"2022-07-20T06:25:40.976720Z","shell.execute_reply.started":"2022-07-20T06:25:25.569578Z","shell.execute_reply":"2022-07-20T06:25:40.975196Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"id":"SklwCF_lVYVx","execution":{"iopub.status.busy":"2022-07-20T06:25:54.066650Z","iopub.execute_input":"2022-07-20T06:25:54.067421Z","iopub.status.idle":"2022-07-20T06:25:54.074218Z","shell.execute_reply.started":"2022-07-20T06:25:54.067378Z","shell.execute_reply":"2022-07-20T06:25:54.072980Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"try:\n    import h5py\nexcept:\n    !pip install h5py\nfinally:    \n    import h5py","metadata":{"id":"-cZ9NgkUVYWI","execution":{"iopub.status.busy":"2022-07-20T06:25:54.076036Z","iopub.execute_input":"2022-07-20T06:25:54.076996Z","iopub.status.idle":"2022-07-20T06:25:54.271683Z","shell.execute_reply.started":"2022-07-20T06:25:54.076955Z","shell.execute_reply":"2022-07-20T06:25:54.270384Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def torch_stats(): \n    torch_version = \".\".join(torch.__version__.split(\".\")[:2])\n    print('torch version:',torch_version)\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print('Using device:', device)\n    dtype = torch.float32\n        \n    if device.type == 'cuda':\n        cuda_version  = torch.__version__.split(\"+\")[-1]\n        print(\"cuda: \", cuda_version)\n        \n        torch.set_default_tensor_type(torch.cuda.FloatTensor)\n        print('Cuda is available:',torch.cuda.is_available())\n\n        n_devices = torch.cuda.device_count()\n        print('number of devices: %d'%(n_devices))\n\n        for cnt_device in range(n_devices):\n            print(torch.cuda.get_device_name(cnt_device))\n            print('Memory Usage:')\n            print('Allocated:', round(torch.cuda.memory_allocated(cnt_device)/1024**3,1), 'GB')\n            print('Cached:   ', round(torch.cuda.memory_reserved(cnt_device)/1024**3,1), 'GB')\n        # dtype = torch.cuda.FloatTensor\n        \n    torch.set_default_dtype(dtype) # float32\n    print('default data type:',dtype)\n    \n    num_workers=os.cpu_count()\n    print ('available number of workers (CPU cores):',num_workers)\n    \n    return device, dtype, num_workers\n#-------------------------------\ndef torch_seed(seed = 42, deterministic = True):\n    random.seed(seed) # random and transforms\n    np.random.seed(seed) #numpy\n    torch.manual_seed(seed) #cpu\n    torch.cuda.manual_seed(seed) #gpu\n    torch.backends.cudnn.deterministic=deterministic #cudnn    \n    \ndevice, dtype, num_workers = torch_stats()\ntorch_seed(seed = 2, deterministic = True)","metadata":{"id":"osWheWCBFDPD","outputId":"c3d6fe52-57cb-41ee-d311-9dc677581be0","execution":{"iopub.status.busy":"2022-07-20T06:25:54.273366Z","iopub.execute_input":"2022-07-20T06:25:54.273781Z","iopub.status.idle":"2022-07-20T06:25:54.370577Z","shell.execute_reply.started":"2022-07-20T06:25:54.273725Z","shell.execute_reply":"2022-07-20T06:25:54.369155Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"num_workers = 0","metadata":{"id":"zQkqUBOE8ZDv","execution":{"iopub.status.busy":"2022-07-20T06:25:54.372651Z","iopub.execute_input":"2022-07-20T06:25:54.374037Z","iopub.status.idle":"2022-07-20T06:25:54.383951Z","shell.execute_reply.started":"2022-07-20T06:25:54.373991Z","shell.execute_reply":"2022-07-20T06:25:54.382640Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autocor(x, n_fft = None):\n    if n_fft is None: n_fft =  2*x.shape[1]\n    x   = torch.atleast_2d(torch.as_tensor(x))\n    sp  = torch.fft.fft(x, n =n_fft, dim = -1) \n    sp  = (sp*sp.conj()).real     \n    return torch.fft.ifft(sp, n =n_fft, dim = -1)[:,:n_fft//2].real \n\ndef square_filter(x, fp, lp, real_val = True):\n    x     = torch.atleast_2d(torch.as_tensor(x))\n    n_fft =  x.shape[1]\n    sp    = torch.fft.fft(x, n =n_fft, dim = -1)  \n    sp    = _square_filter_(sp, fp, lp, n_fft, real_val = True)\n    out   = torch.fft.ifft(sp, n =n_fft, dim = -1)\n    if real_val: out = out.real\n    return out\n\ndef hilbert(x):\n    n_fft =  x.shape[1]\n    return square_filter(x, 0, n_fft//2, real_val = False)\n\ndef _square_filter_(sp, fp, lp, n_fft, real_val = True):\n    sp[:,:fp] = 0\n    sp[:,lp:n_fft//2] = 0\n    if real_val:\n        sp[:,n_fft - fp +1:] = 0    \n        sp[:,n_fft//2:n_fft//2+(n_fft//2-lp) +1 ] = 0\n    else:\n        sp[:,n_fft//2:] = 0\n    return sp\n\ndef transform(x, fp, lp):\n    n_fft =  2*x.shape[1]\n    x     = torch.atleast_2d(torch.as_tensor(x))\n    sp    = torch.fft.fft(x, n =n_fft, dim = -1) \n    sp    = _square_filter_(sp, fp, lp, n_fft, real_val = True)\n    sp    = (sp*sp.conj()).real     \n    return torch.fft.ifft(sp, n =n_fft, dim = -1)[:,:x.shape[1]].real \n\ndef transform(x, fp, lp):    \n    return square_filter(x, fp, lp, real_val = True)","metadata":{"id":"Gdud6OAdVYWN","execution":{"iopub.status.busy":"2022-07-20T06:25:54.386005Z","iopub.execute_input":"2022-07-20T06:25:54.387508Z","iopub.status.idle":"2022-07-20T06:25:54.406168Z","shell.execute_reply.started":"2022-07-20T06:25:54.387460Z","shell.execute_reply":"2022-07-20T06:25:54.404757Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Data import","metadata":{"id":"hI_ryK0ZVYXK"}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')\n# dataset = h5py.File('/content/drive/MyDrive/dataset_.hdf5', 'r')","metadata":{"id":"AWHZgDswV43X","execution":{"iopub.status.busy":"2022-07-20T06:25:54.408395Z","iopub.execute_input":"2022-07-20T06:25:54.409635Z","iopub.status.idle":"2022-07-20T06:25:54.423666Z","shell.execute_reply.started":"2022-07-20T06:25:54.409592Z","shell.execute_reply":"2022-07-20T06:25:54.422230Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"try:\n    import gdown\nexcept:\n    !pip install gdown\nfinally:\n    import gdown\n\nurl = 'https://drive.google.com/uc?export=download&id=1IaFJfZewg8JkfU8034gDiog0oP9mEHI3'\noutput = 'dataset_.hdf5'\ngdown.download(url, output, quiet=False)\ndataset = h5py.File('dataset_.hdf5', 'r')","metadata":{"id":"bXFPpHgqBBco","outputId":"e738ddc8-3371-4171-99d4-a439b0641b53","execution":{"iopub.status.busy":"2022-07-20T06:25:54.431289Z","iopub.execute_input":"2022-07-20T06:25:54.432492Z","iopub.status.idle":"2022-07-20T06:26:44.831068Z","shell.execute_reply.started":"2022-07-20T06:25:54.432446Z","shell.execute_reply":"2022-07-20T06:26:44.829458Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"fs = 50e3\n","metadata":{"id":"uWiFu88pVYXK","execution":{"iopub.status.busy":"2022-07-20T06:26:44.840081Z","iopub.execute_input":"2022-07-20T06:26:44.843355Z","iopub.status.idle":"2022-07-20T06:26:44.852766Z","shell.execute_reply.started":"2022-07-20T06:26:44.843261Z","shell.execute_reply":"2022-07-20T06:26:44.851081Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class HD5Dataset(nn.Module):\n\n    def __init__(self, ds, parts, signal_size, real_size = 1e3, transform=None, device = None):\n        self.ds = ds\n        self.parts = parts\n        self.signal_size = signal_size\n        self.transform = transform\n        self._len = 0\n        self.ncls  = 0\n        self.signals_in_class = []\n        self.signals_in_part  = []\n        self.classes_in_part  = []\n        self.real_size = int(real_size)\n        self.n_parts = len(self.parts)\n        for part in self.parts:\n            shape = self.ds[part].shape\n            self.signals_in_part += [shape[0]*(shape[1]//self.signal_size)]\n            self.ncls  += shape[0]\n            self.signals_in_class +=[shape[1]//self.signal_size]\n            self._len += self.signals_in_part[-1]\n            self.classes_in_part +=[shape[0]]\n        # self.classes_in_part = torch.tensor(self.classes_in_part)\n        # self.signals_in_part = torch.tensor(self.signals_in_part) \n        # self.signals_in_class = torch.tensor(self.signals_in_class) \n        if device is not None:\n            self.device = device\n        else:\n          self.device = 'cpu'\n\n    def incpect(self):\n        print('signals_in_part',self.signals_in_part)\n        print('signals_in_class',self.signals_in_class)\n        print('n cls',self.ncls)\n        print('len',self.__len__())\n        print('n_parts',self.n_parts)\n        print('classes_in_part',self.classes_in_part)\n    \n    def idx_2_position(self, idx):\n        part = idx//self.signals_in_part[0]\n        idx  = idx - self.signals_in_part[0]*part\n        source = idx// self.signals_in_class[part] \n        segment = idx - self.signals_in_class[part] *source\n        fp = segment*self.signal_size\n        lp = (segment+1)*self.signal_size\n        return part, source, fp, lp\n    \n    def position_2_class(self, part, source):\n        return sum(self.classes_in_part[:part])+source\n\n    def __len__(self):\n        return self._len\n\n    def __getitem__(self, idx):\n      \n        part, source, fp, lp = self.idx_2_position(idx)\n\n        signal = self.ds[self.parts[part]][source,fp:lp]\n        label  = self.position_2_class(part, source)\n\n        if self.transform:\n            signal = self.transform(signal)\n\n        return torch.as_tensor(signal).to(self.device).unsqueeze(0), torch.as_tensor(label).to(self.device)","metadata":{"id":"NE66D5KZvRNP","execution":{"iopub.status.busy":"2022-07-20T06:26:44.858457Z","iopub.execute_input":"2022-07-20T06:26:44.860582Z","iopub.status.idle":"2022-07-20T06:26:44.895667Z","shell.execute_reply.started":"2022-07-20T06:26:44.860537Z","shell.execute_reply":"2022-07-20T06:26:44.893640Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    kwarg = {'generator':torch.Generator(device='cuda')}\nelse:\n    kwarg = {'generator':torch.Generator(device='cpu')}\n    \ndef collate_fn(batch, real_size = int(10e3), device=device):\n  x = torch.stack([data_[0] for data_ in batch]).to(device)\n  scale =  x.shape[2]//real_size\n  x = x.reshape(x.shape[0]*scale, -1, real_size)\n  y = torch.stack([data_[1] for data_ in batch]).repeat_interleave(scale)  \n  return x,y ","metadata":{"execution":{"iopub.status.busy":"2022-07-20T06:26:44.902355Z","iopub.execute_input":"2022-07-20T06:26:44.904558Z","iopub.status.idle":"2022-07-20T06:26:44.922841Z","shell.execute_reply.started":"2022-07-20T06:26:44.904506Z","shell.execute_reply":"2022-07-20T06:26:44.921378Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# \n# # bs = [4,8,16,32,64,128]\n# bs = [32]\n# scales = [10,25,50,75,100,125,150,175,200]\n# for scale in scales:\n#   test_set   = HD5Dataset(dataset,parts = ['x_test_1','x_test_2'], signal_size=int(scale*10e3))\n#   for BATCH_SIZE in bs:\n#     testloader = torch.utils.data.DataLoader(test_set,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, **kwarg)\n#     start = timeit.default_timer()\n#     for x,y in testloader:\n#       x.to(device)\n#       y.to(device)\n#     stop = timeit.default_timer()\n#     print(f'BATCH_SIZE {BATCH_SIZE}, scale {scale}, Time: ', stop - start) \n\n\n","metadata":{"id":"IyRWkpNjERvU","execution":{"iopub.status.busy":"2022-07-20T06:26:44.928723Z","iopub.execute_input":"2022-07-20T06:26:44.929252Z","iopub.status.idle":"2022-07-20T06:26:44.964338Z","shell.execute_reply.started":"2022-07-20T06:26:44.929193Z","shell.execute_reply":"2022-07-20T06:26:44.962348Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# bs = [32,64,128,256]\n# scales = [125,250]\n# for scale in scales:\n#   test_set   = HD5Dataset(dataset,parts = ['x_test_1','x_test_2'], signal_size=int(scale*10e3))\n#   for BATCH_SIZE in bs:\n#     testloader = torch.utils.data.DataLoader(test_set,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, **kwarg)\n#     start = timeit.default_timer()\n#     for x,y in testloader:\n#       x.to(device)\n#       y.to(device)\n#     stop = timeit.default_timer()\n#     print(f'BATCH_SIZE {BATCH_SIZE}, scale {scale}, Time: ', stop - start) ","metadata":{"id":"-_uIJUdUMFLR","execution":{"iopub.status.busy":"2022-07-20T06:26:44.966332Z","iopub.execute_input":"2022-07-20T06:26:44.967468Z","iopub.status.idle":"2022-07-20T06:26:44.984969Z","shell.execute_reply.started":"2022-07-20T06:26:44.967198Z","shell.execute_reply":"2022-07-20T06:26:44.975947Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"SCALE = 50\nBATCH_SIZE = 1\ntest_set = HD5Dataset(dataset,parts = ['x_test_1','x_test_2'],   signal_size=int(SCALE*10e3))\nds       = HD5Dataset(dataset,parts = ['x_train_1','x_train_2'], signal_size=int(SCALE*10e3))","metadata":{"id":"lMvbFk-558Nc","execution":{"iopub.status.busy":"2022-07-20T06:26:44.986920Z","iopub.execute_input":"2022-07-20T06:26:44.987504Z","iopub.status.idle":"2022-07-20T06:26:45.010017Z","shell.execute_reply.started":"2022-07-20T06:26:44.987457Z","shell.execute_reply":"2022-07-20T06:26:45.001767Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_set, val_set = torch.utils.data.random_split(ds, [int(len(ds)*0.7), len(ds)-int(len(ds)*0.7)], **kwarg)","metadata":{"id":"KohrxQV5uS2s","execution":{"iopub.status.busy":"2022-07-20T06:26:45.016280Z","iopub.execute_input":"2022-07-20T06:26:45.017481Z","iopub.status.idle":"2022-07-20T06:26:48.792477Z","shell.execute_reply.started":"2022-07-20T06:26:45.017427Z","shell.execute_reply":"2022-07-20T06:26:48.786946Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"trainloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True,  collate_fn=collate_fn, **kwarg)\nvalloader   = torch.utils.data.DataLoader(val_set,   batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, **kwarg)\ntestloader  = torch.utils.data.DataLoader(test_set,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, **kwarg)","metadata":{"id":"oyzO_C_JuS5-","execution":{"iopub.status.busy":"2022-07-20T06:26:48.799178Z","iopub.execute_input":"2022-07-20T06:26:48.802675Z","iopub.status.idle":"2022-07-20T06:26:48.816760Z","shell.execute_reply.started":"2022-07-20T06:26:48.802615Z","shell.execute_reply":"2022-07-20T06:26:48.814547Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\ndef correct_sizes(sizes):\n    corrected_sizes = [s if s % 2 != 0 else s - 1 for s in sizes]\n    return corrected_sizes\n\ndef pass_through(X):\n    return X\n\nclass InceptionModule(nn.Module):\n    def __init__(self, in_channels, n_filters, kernel_sizes=[9, 19, 39], bottleneck_channels=32, activation=nn.ReLU(), return_indices=False):\n        \"\"\"\n        : param in_channels\t\t\t\tNumber of input channels (input features)\n        : param n_filters\t\t\t\tNumber of filters per convolution layer => out_channels = 4*n_filters\n        : param kernel_sizes\t\t\tList of kernel sizes for each convolution.\n                                        Each kernel size must be odd number that meets -> \"kernel_size % 2 !=0\".\n                                        This is nessesery because of padding size.\n                                        For correction of kernel_sizes use function \"correct_sizes\". \n        : param bottleneck_channels\t\tNumber of output channels in bottleneck. \n                                        Bottleneck wont be used if nuber of in_channels is equal to 1.\n        : param activation\t\t\t\tActivation function for output tensor (nn.ReLU()). \n        : param return_indices\t\t\tIndices are needed only if we want to create decoder with InceptionTranspose with MaxUnpool1d. \n        \"\"\"\n        super(InceptionModule, self).__init__()\n        self.return_indices=return_indices\n        if in_channels > 1:\n            self.bottleneck = nn.Conv1d(\n                                in_channels=in_channels, \n                                out_channels=bottleneck_channels, \n                                kernel_size=1, \n                                stride=1, \n                                bias=False\n                                )\n        else:\n            self.bottleneck = pass_through\n            bottleneck_channels = 1\n\n        self.conv_from_bottleneck_1 = nn.Conv1d(\n                                        in_channels=bottleneck_channels, \n                                        out_channels=n_filters, \n                                        kernel_size=kernel_sizes[0], \n                                        stride=1, \n                                        padding=kernel_sizes[0]//2, \n                                        bias=False\n                                        )\n        self.conv_from_bottleneck_2 = nn.Conv1d(\n                                        in_channels=bottleneck_channels, \n                                        out_channels=n_filters, \n                                        kernel_size=kernel_sizes[1], \n                                        stride=1, \n                                        padding=kernel_sizes[1]//2, \n                                        bias=False\n                                        )\n        self.conv_from_bottleneck_3 = nn.Conv1d(\n                                        in_channels=bottleneck_channels, \n                                        out_channels=n_filters, \n                                        kernel_size=kernel_sizes[2], \n                                        stride=1, \n                                        padding=kernel_sizes[2]//2, \n                                        bias=False\n                                        )\n        self.max_pool = nn.MaxPool1d(kernel_size=3, stride=1, padding=1, return_indices=return_indices)\n        self.conv_from_maxpool = nn.Conv1d(\n                                    in_channels=in_channels, \n                                    out_channels=n_filters, \n                                    kernel_size=1, \n                                    stride=1,\n                                    padding=0, \n                                    bias=False\n                                    )\n        self.batch_norm = nn.BatchNorm1d(num_features=4*n_filters)\n        self.activation = activation\n\n    def forward(self, X):\n        # step 1\n        Z_bottleneck = self.bottleneck(X)\n        Z_maxpool = self.max_pool(X)\n        # step 2\n        Z1 = self.conv_from_bottleneck_1(Z_bottleneck)\n        Z2 = self.conv_from_bottleneck_2(Z_bottleneck)\n        Z3 = self.conv_from_bottleneck_3(Z_bottleneck)\n        Z4 = self.conv_from_maxpool(Z_maxpool)\n        # step 3 \n        Z = torch.cat([Z1, Z2, Z3, Z4], axis=1)\n        Z = self.activation(self.batch_norm(Z))\n        return Z\n\n\nclass InceptionModule(nn.Module):\n    def __init__(self, in_channels, n_filters=32, kernel_sizes=[9,19,39], bottleneck_channels=32, use_residual=True, activation=nn.ReLU(), return_indices=False):\n        super(InceptionModule, self).__init__()\n        self.use_residual = use_residual\n        self.return_indices = return_indices\n        self.activation = activation\n        self.inception_1 = InceptionBlock(\n                            in_channels=in_channels,\n                            n_filters=n_filters,\n                            kernel_sizes=kernel_sizes,\n                            bottleneck_channels=bottleneck_channels,\n                            activation=activation,\n                            return_indices=return_indices\n                            )\n        self.inception_2 = InceptionBlock(\n                            in_channels=4*n_filters,\n                            n_filters=n_filters,\n                            kernel_sizes=kernel_sizes,\n                            bottleneck_channels=bottleneck_channels,\n                            activation=activation,\n                            return_indices=return_indices\n                            )\n        self.inception_3 = InceptionBlock(\n                            in_channels=4*n_filters,\n                            n_filters=n_filters,\n                            kernel_sizes=kernel_sizes,\n                            bottleneck_channels=bottleneck_channels,\n                            activation=activation,\n                            return_indices=return_indices\n                            )\n        if self.use_residual:\n            self.residual = nn.Sequential(\n                                nn.Conv1d(\n                                    in_channels=in_channels, \n                                    out_channels=4*n_filters, \n                                    kernel_size=1,\n                                    stride=1,\n                                    padding=0\n                                    ),\n                                nn.BatchNorm1d(\n                                    num_features=4*n_filters\n                                    )\n                                )\n\n    def forward(self, X):\n        Z = self.inception_1(X)\n        Z = self.inception_2(Z)\n        Z = self.inception_3(Z)\n        if self.use_residual:\n            Z = Z + self.residual(X)\n            Z = self.activation(Z)\n        return Z\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-20T08:57:23.563160Z","iopub.execute_input":"2022-07-20T08:57:23.563668Z","iopub.status.idle":"2022-07-20T08:57:25.652523Z","shell.execute_reply.started":"2022-07-20T08:57:23.563574Z","shell.execute_reply":"2022-07-20T08:57:25.651104Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class Flatten(nn.Module):\n    def __init__(self, out_features):\n        super(Flatten, self).__init__()\n        self.output_dim = out_features\n\n    def forward(self, x):\n        return x.view(-1, self.output_dim)\n\nclass Reshape(nn.Module):\n    def __init__(self, shape):\n        super(Reshape, self).__init__()\n        self.out_shape = shape\n\n    def forward(self, x):\n        return x.view(-1, *self.out_shape)\n\nmodel = nn.Sequential(\n                    Reshape(shape=(1,10_000)),\n                    InceptionModule(\n                        in_channels=1, \n                        n_filters=32, \n                        kernel_sizes=[9,19,39],\n                        bottleneck_channels=32,\n                        use_residual=True,\n                        activation=nn.ReLU()\n                    ),\n                    InceptionModule(\n                        in_channels=32*4, \n                        n_filters=32, \n                        kernel_sizes=[9,19,39],\n                        bottleneck_channels=32,\n                        use_residual=True,\n                        activation=nn.ReLU()\n                    ),\n                    nn.AdaptiveAvgPool1d(output_size=1),\n                    Flatten(out_features=32*4*1),\n                    nn.Linear(in_features=4*32*1, out_features=40)\n        )","metadata":{"execution":{"iopub.status.busy":"2022-07-20T06:26:48.990717Z","iopub.execute_input":"2022-07-20T06:26:48.991158Z","iopub.status.idle":"2022-07-20T06:26:49.016926Z","shell.execute_reply.started":"2022-07-20T06:26:48.991128Z","shell.execute_reply":"2022-07-20T06:26:49.015661Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint('Number of trainable parameters for the model: %d' % (num_params))\n\nnum_params = sum(p.numel() for p in model.parameters() )\nprint('Number of all parameters for the model: %d' % (num_params))\n\nfrom torchsummary import summary\nsummary(model,(1,10000))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T06:26:49.018849Z","iopub.execute_input":"2022-07-20T06:26:49.021338Z","iopub.status.idle":"2022-07-20T06:26:55.967824Z","shell.execute_reply.started":"2022-07-20T06:26:49.021261Z","shell.execute_reply":"2022-07-20T06:26:55.966366Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"LR = 0.0009\n\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\ncriterion = criterion.to(device)\n\n\n# trainable_parameters = filter(lambda p: p.requires_grad, model.parameters())\noptimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n\ndef initialize_weights(m):\n  if isinstance(m, nn.Conv1d):\n      nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n      if m.bias is not None:\n          nn.init.constant_(m.bias.data, 0)\n  elif isinstance(m, nn.BatchNorm1d):\n      nn.init.constant_(m.weight.data, 1)\n      nn.init.constant_(m.bias.data, 0)      \n  if type(m) == nn.Linear:\n        nn.init.xavier_uniform(m.weight)   \n        if m.bias is not None:\n          nn.init.constant_(m.bias.data, 0) \n\nmodel.apply(initialize_weights)","metadata":{"id":"tft3w6iZCcK1","outputId":"08bf8ea0-9d06-4f66-f588-aef036c959f1","execution":{"iopub.status.busy":"2022-07-20T06:26:55.970041Z","iopub.execute_input":"2022-07-20T06:26:55.970887Z","iopub.status.idle":"2022-07-20T06:26:55.994152Z","shell.execute_reply.started":"2022-07-20T06:26:55.970842Z","shell.execute_reply":"2022-07-20T06:26:55.992905Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def accuracy(y_pred, y):\n    cls_pred = y_pred.argmax(1, keepdim=True)    \n    correct_cls = cls_pred.eq(y.view_as(cls_pred)).sum()\n    acc = correct_cls.float() / y.shape[0]\n    return acc\n    \n#-----------------------------\ndef train(model, dataloader, optimizer, criterion, metric, device):\n\n    epoch_loss = 0\n    epoch_acc  = 0\n\n    model.train()\n\n    for (x, y) in dataloader:#tqdm(dataloader, desc=\"Training\", leave=False):\n\n        x = x.to(device)\n        y = y.to(device)\n\n        optimizer.zero_grad()\n\n        y_pred = model.forward(x)\n\n        loss = criterion(y_pred, y)\n        acc  = metric( y_pred, y)\n\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        epoch_acc  += acc.item()\n\n    return epoch_loss / len(dataloader), epoch_acc / len(dataloader)\n\n\n#--------------------------    \ndef asserts(model, dataloader, optimizer, criterion, metric, device):\n\n    for (x, y) in  dataloader:#tqdm(dataloader, desc=\"Training\", leave=False):\n\n        x = x.to(device)\n        y = y.to(device)\n\n    return x,y\n#--------------------------\ndef evaluate(model, dataloader, criterion, metric, device):\n\n    epoch_loss = 0\n    epoch_acc  = 0\n\n    model.eval()\n\n    with torch.no_grad():\n        \n        for (x, y) in dataloader:#tqdm(dataloader, desc=\"Evaluating\", leave=False):\n\n            x = x.to(device)\n            y = y.to(device)\n\n            y_pred = model.forward(x)\n\n            loss = criterion(y_pred, y)\n            acc  = metric( y_pred, y)\n\n            epoch_loss += loss.item()\n            epoch_acc  += acc.item()\n\n    return epoch_loss / len(dataloader), epoch_acc / len(dataloader)\n#-------------------\ndef predicts(model, dataloader, device):\n\n    epoch_loss = 0\n    epoch_acc  = 0\n\n    model.eval()\n\n    y_s = []\n    y_preds = []\n    with torch.no_grad():\n        \n        for (x, y) in dataloader:#tqdm(dataloader, desc=\"Evaluating\", leave=False):\n\n            x = x.to(device)\n            y = [y.to(device).data.cpu().numpy()]\n          \n            y_pred = +[ model.forward(x).data.cpu().numpy() ]\n\n    return np.asarray(y_s), np.asarray(y_preds)\n#-------------------\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"id":"buGeqqd2CcNa","execution":{"iopub.status.busy":"2022-07-20T06:26:55.996125Z","iopub.execute_input":"2022-07-20T06:26:55.996726Z","iopub.status.idle":"2022-07-20T06:26:57.517433Z","shell.execute_reply.started":"2022-07-20T06:26:55.996683Z","shell.execute_reply":"2022-07-20T06:26:57.515977Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 200\n\ntrain_loss = torch.zeros(EPOCHS)\nvalid_loss = torch.zeros(EPOCHS)\ntrain_acc  = torch.zeros(EPOCHS)\nvalid_acc  = torch.zeros(EPOCHS)\n\nbest_valid_loss = float('inf')\nbest_epoch = 0\n\nfor epoch in range(EPOCHS):#trange(EPOCHS, desc=\"Epochs\"):\n\n    start_time = time.monotonic()\n\n    train_loss[epoch], train_acc[epoch] = train(model, \n                                                trainloader, \n                                                optimizer, \n                                                criterion,\n                                                accuracy,\n                                                device)\n    \n    valid_loss[epoch], valid_acc[epoch] = evaluate(model, \n                                                   valloader, \n                                                   criterion, \n                                                   accuracy,\n                                                   device)\n\n    if valid_loss[epoch] < best_valid_loss:\n        best_valid_loss = valid_loss[epoch]\n        best_epoch = epoch\n        torch.save(model.state_dict(), 'best_model.pt')\n\n    epoch_mins, epoch_secs = epoch_time(start_time, time.monotonic())\n    # if epoch%2 == 1:    # print every 2 epochs:\n    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss[epoch]:.3f} | Train Acc: {train_acc[epoch]*100:.2f}%')\n    print(f'\\t Val. Loss: {valid_loss[epoch]:.3f} |  Val. Acc: {valid_acc[epoch]*100:.2f}%')\n\nmodel.load_state_dict(torch.load('best_model.pt'))\ntest_loss, test_acc = evaluate(model, valloader, criterion, accuracy, device)\nprint(10*'--',f'\\nbest epoch {best_epoch}: Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')","metadata":{"id":"dFNQu-1QuTAu","outputId":"1e7da798-0f5b-428d-d581-9ead1580b274","execution":{"iopub.status.busy":"2022-07-20T06:26:57.519484Z","iopub.execute_input":"2022-07-20T06:26:57.520322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x,y = asserts(model, \n              trainloader, \n              optimizer, \n              criterion,\n              accuracy,\n              device)","metadata":{"id":"WroSHR86O9QI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x.shape,y.shape)","metadata":{"id":"tIenKd5RPJYv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('best_model.pt'))\ntest_loss, test_acc = evaluate(model, testloader, criterion, accuracy, device)\nprint(10*'--',f'\\nbest epoch {best_epoch}: Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')","metadata":{"id":"Yog2zSrneg9Z","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predicts(model, dataloader, device):\n\n    epoch_loss = 0\n    epoch_acc  = 0\n\n    model.eval()\n\n    y_s = np.array([])\n    y_preds = np.array([])\n    with torch.no_grad():\n        \n        for (x, y) in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n\n            x = x.to(device)\n            y_s = np.append(y_s,y.to(device).data.cpu().numpy())\n\n            outs = torch.argmax(model.forward(x), dim = -1)\n\n            y_preds = np.append(y_preds, outs.data.cpu().numpy() )\n    return np.asarray(y_s), np.asarray(y_preds)","metadata":{"id":"SgGVNOI0zwlx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y, y_pred = predicts(model, testloader, device)","metadata":{"id":"iy3HANnP0f5i","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(y)","metadata":{"id":"WU_CAPhb1dRz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot((y_pred))","metadata":{"id":"1jLeZEZP2jDF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(y_pred)\ndf.to_csv('inceptiontime.csv')","metadata":{"id":"W17sLfu2q3J8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Ld4qCBTiGPmt"},"execution_count":null,"outputs":[]}]}